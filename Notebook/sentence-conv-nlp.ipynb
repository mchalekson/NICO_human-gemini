{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15d6829",
   "metadata": {},
   "source": [
    "# Sentence Convergence w/ NLP\n",
    "\n",
    "cosine similarity might be able to work best as the output metric to tell what idea is converging/diverging. Because it tracks the similarities between points of comparison.\n",
    "\n",
    "But then checking the length of transcript for a particular person. Do we break it up by sentence. \n",
    "- What is considered that \"smallest unit?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5a710e",
   "metadata": {},
   "source": [
    "# Setting up the files for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5575b089",
   "metadata": {},
   "source": [
    "## Idea 1 - Clean and reproducible - placebo\n",
    "\n",
    "This just cleans up the transcript so it is cleanly viewed. Cleans up text format. If it is empty transcript, removes row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c073c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 255 utterances for session 2021_05_21_ABI_S15_ABI\n",
      "        global_session                speaker   timestamp  global_timestamp_sec                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     transcript\n",
      "2021_05_21_ABI_S15_ABI             Brad Smith 00:00-00:37                 615.0                                                                                                                       Well, um, yeah, let's maybe start some introductions. We're beginning the obviously by the third breakout session and all of this stuff beginning to know each other pretty well. So, uh, I'll just read them out here. Well, let me I've already introduced. Oh man, I'm a chemistry based person and optical imaging is primarily what I do. So the lack of deep tissue imaging is the problem I'm trying to avoid or trying to get around. Uh, but let's just see what other modalities that we've got there. So, um, Anarude, maybe start with you because you're you're not eating.\n",
      "2021_05_21_ABI_S15_ABI             Brad Smith 00:00-00:07                 615.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         which I will do, but whoever's birthday is closest to this day, you're in trouble, so it is an honor system I suppose.\n",
      "2021_05_21_ABI_S15_ABI          Carolyn Bayer 00:00-00:52                 615.0 could be used, anything that's absorbing light or another form of energy could in theory be used to generate an acoustic signal. Um, and so the the problem we'll run into though with deep tissue imaging is sensitivity. Um, so if you had a genetic reporter, you're not likely generating sufficient concentrations at depth that you would have the sensitivity necessary to detect it. Um, you know, we think a lot though about redesigning our systems for improved signal to noise, you know, improved light delivery, you know, and all of those things can work in your favor when you're trying to really push the limits on sensitivity, but we obviously have some big goals and big challenges.\n",
      "2021_05_21_ABI_S15_ABI             Sixian You 00:00-00:23                 615.0                                                                                                                                                                                                                                                                                                                                                              sound the unscattering property, right? So if we know the signal is there, can we use ultrasound to confine the signal there, to modulate the signal, and then to get the signal back. So I think that could be very interesting and I need to learn more about Barbara's research on electrodes as wave guide. Uh, it sounds really fascinating.\n",
      "2021_05_21_ABI_S15_ABI          Carolyn Bayer 00:00-00:06                 615.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   determining how to send light in in a way that it scatters deeper in tissue.\n",
      "2021_05_21_ABI_S15_ABI             Brad Smith 00:01-00:06                 616.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Genia, you're the one that's pioneering it. You've you've\n",
      "2021_05_21_ABI_S15_ABI Yevgenia Kozorovitskiy 00:06-00:32                 621.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    I I think yes, uh, but primarily by having advantages of gentle illumination and relatively rapid access to 3D information.\n",
      "2021_05_21_ABI_S15_ABI             Brad Smith 00:07-00:34                 622.0                                                                                                                                                                                                                                                                One thing that I I've I've definitely heard some talks where people just image what they call the the early photons. So the ones that are the the least the least the least scattered. So you only collect the first 5% of the signal on the assumption that it got there first was the least scattered and so it's going to have the best resolution and you toss out 95% of the the rest of it. I don't know if that's a feasible technology.\n",
      "2021_05_21_ABI_S15_ABI             Brad Smith 00:09-00:12                 624.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Um, well,\n",
      "2021_05_21_ABI_S15_ABI          Barbara Smith 00:12-00:15                 627.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               No, nobody's going to volunteer.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your file\n",
    "df = pd.read_csv(\"/Users/maxchalekson/Projects/NICO-Research/NICO_human-gemini/Data/utterance_data_aligned_full.csv\")\n",
    "\n",
    "# --- Basic cleanup ---\n",
    "df['transcript'] = df['transcript'].astype(str).str.strip()\n",
    "df = df[df['transcript'] != \"\"]\n",
    "df = df.dropna(subset=['transcript'])\n",
    "\n",
    "# Sort chronologically\n",
    "df = df.sort_values(by=['global_session', 'global_timestamp_sec']).reset_index(drop=True)\n",
    "\n",
    "# Filter for specific session\n",
    "session_id = \"2021_05_21_ABI_S15_ABI\"\n",
    "df_session = df[df['global_session'] == session_id].reset_index(drop=True)\n",
    "\n",
    "# Summary\n",
    "print(f\"Loaded {len(df_session)} utterances for session {session_id}\")\n",
    "\n",
    "# Show preview\n",
    "preview_cols = ['global_session', 'speaker', 'timestamp', 'global_timestamp_sec', 'transcript']\n",
    "print(df_session[preview_cols].head(10).to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ad1f0",
   "metadata": {},
   "source": [
    "## Idea 2 - Sentence Level Unit-ideas\n",
    "\n",
    "(the main way how the excel file will be processed.)\n",
    "\n",
    "Deletes the backchannel utterances (e.g. \"okay\", \"yes\", \"right\", \"sounds good\")\n",
    "\n",
    "Splits up transcript by sentence by speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a41c47c",
   "metadata": {},
   "source": [
    "Couple of things done here:\n",
    "\n",
    "1. Breaking the excel files' row into sentences\n",
    "\n",
    "In the raw file, one \"row\" might be a short filler (\"Yeah.\") or a long paragraph with multiple ideas. That makes it hard to comapre ideas fairly. So we split each row into sentences. Now every chunk is about the same size, which makes our simililarity scores more meaningful.\n",
    "\n",
    "2. Keeping the speaker\n",
    "\n",
    "We always keep track of who said it. This way we can tell if an idea is picked up by someone-else (cross-speaker) or if the same person is just adding more details (same-speaker)\n",
    "\n",
    "3. Tagging the type of sentence\n",
    "\n",
    "We give each sentence a quick label like `Proposal/Offer`, `Acceptance`, `Question`, or `Inform/Report`. This is important because not every sentence is an \"idea\". For example, \"Sounds good.\" is an acceptane, not a new idea. Tagging them stops these from messing up our idea similarity results, while still letting us track decisions.\n",
    "\n",
    "4. Making the timeline cleans\n",
    "\n",
    "Sometimes timestamps in the fiel go backwards or have ties. We fix this by nudging times forward by 0.001 seconds if needed. This tiny change doesn't affect the analysis, but it keeps our data in the right order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d077c38",
   "metadata": {},
   "source": [
    "### implementing co-similarity (SBERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687625ce",
   "metadata": {},
   "source": [
    "all of this still tests the idea if Gemini is even capable of defining a convergence to solution, even if NLP topics are used within the transcript, based on all this code run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257167b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done. Kept all rows: 16467.\n",
      "• Wrote full file: /Users/maxchalekson/Projects/NICO-Research/NICO_human-gemini/Data/utterance_data_aligned_full_continuous_overwritten.csv\n",
      "• Wrote ABI S15-only file: /Users/maxchalekson/Projects/NICO-Research/NICO_human-gemini/Data/utterance_data_ABI_S15_continuous_overwritten.csv\n",
      "\n",
      "Per-master-session ABI_S15 durations:\n",
      "stitch_key(session)  rows  resets_detected  duration_sec duration_hms\n",
      " 2021_05_21_ABI_S15   255                6        3515.0      0:58:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/lphw45ds14n5t74zwjdfybx40000gn/T/ipykernel_95466/3809272097.py:161: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['00:00-00:37' '00:38-00:46' '00:46-00:56' '00:56-01:00' '01:00-01:06'\n",
      " '01:07-01:59' '02:00-02:03' '02:03-02:52' '02:52-02:54' '02:56-03:44'\n",
      " '03:44-03:50' '03:50-05:01' '05:01-05:02' '05:02-05:52' '05:52-06:22'\n",
      " '06:22-06:45' '06:45-06:51' '06:53-07:27' '07:27-07:30' '07:30-07:31'\n",
      " '07:35-07:37' '07:37-08:22' '08:22-08:26' '08:27-09:00' '09:00-09:27'\n",
      " '09:27-09:30' '09:30-09:50' '09:50-09:54' '09:54-10:00' '10:00-10:03'\n",
      " '10:03-10:59' '10:59-11:06' '11:08-11:11' '11:11-11:14' '11:15-11:21'\n",
      " '11:21-11:36' '11:36-11:43' '11:43-11:59' '11:59-12:06' '12:06-12:23'\n",
      " '12:28-12:36' '12:44-12:59' '13:00-13:04' '13:04-13:10' '13:12-13:15'\n",
      " '13:16-13:29' '13:29-13:47' '13:49-14:29' '14:29-14:30' '14:30-14:30'\n",
      " '14:30-14:31' '14:31-14:31' '14:31-14:39' '14:40-14:45' '14:45-14:46'\n",
      " '14:46-15:09' '15:09-15:18' '15:18-15:19' '15:19-15:19' '15:19-15:19'\n",
      " '15:19-15:20' '15:20-15:22' '15:22-15:23' '15:23-15:24' '15:24-15:24'\n",
      " '15:24-15:25' '15:25-15:26' '15:27-15:39' '15:39-15:39' '15:39-15:39'\n",
      " '15:39-15:39' '15:39-15:39' '15:39-15:39' '15:39-15:39' '15:39-15:39'\n",
      " '15:39-15:39' '15:39-15:39' '15:39-15:39' '15:39-15:39' '15:39-15:39'\n",
      " '15:39-15:39' '15:40-15:45' '15:45-16:11' '16:11-16:31' '16:31-16:44'\n",
      " '16:44-17:09' '17:09-17:25' '17:29-17:36' '17:36-17:53' '17:54-17:54'\n",
      " '17:55-18:12' '18:12-18:18' '18:18-18:55' '18:55-18:55' '18:56-19:06'\n",
      " '19:07-19:21' '19:21-19:22' '19:22-19:22' '19:23-19:40' '19:40-20:02'\n",
      " '20:02-20:24' '20:24-20:53' '20:53-21:12' '21:12-21:32' '21:32-21:32'\n",
      " '21:33-21:53' '21:53-22:11' '22:11-22:11' '22:11-22:11' '22:11-22:11'\n",
      " '22:11-22:53' '22:53-23:16' '23:16-23:24' '23:24-23:40' '23:40-23:41'\n",
      " '23:41-24:16' '24:18-24:24' '24:24-24:24' '24:24-24:24' '24:24-24:31'\n",
      " '24:31-24:40' '24:40-25:25' '25:25-25:53' '25:53-25:53' '25:53-25:59'\n",
      " '25:59-26:12' '26:12-26:31' '26:31-26:54' '26:54-27:46' '27:47-28:33'\n",
      " '28:33-28:57' '28:57-28:58' '28:58-29:05' '29:05-29:05' '29:05-29:21'\n",
      " '29:21-29:33' '29:33-29:35' '29:35-29:57' '30:07-30:24' '30:24-31:11'\n",
      " '31:23-32:06' '32:06-32:14' '32:14-32:58' '32:58-33:25' '33:25-34:58'\n",
      " '34:58-35:05' '35:05-35:35' '35:35-36:06' '36:06-36:31' '36:31-36:54'\n",
      " '36:54-37:01' '37:02-37:02' '37:02-37:07' '37:07-37:18' '37:18-37:27'\n",
      " '37:27-37:54' '37:55-38:48' '38:49-39:06' '39:07-39:23' '39:23-39:36'\n",
      " '39:36-39:55' '39:55-40:31' '40:31-41:02' '41:02-41:03' '41:03-41:05'\n",
      " '41:05-41:12' '41:20-41:21' '41:21-41:27' '41:27-41:35' '41:35-41:41'\n",
      " '41:42-41:42' '41:42-41:48' '41:48-41:57' '41:57-42:08' '42:08-42:11'\n",
      " '42:11-42:26' '42:27-42:37' '42:37-42:46' '42:46-42:55' '42:55-42:55'\n",
      " '42:57-42:58' '42:58-43:26' '43:29-43:32' '43:32-43:49' '43:49-43:53'\n",
      " '43:53-43:56' '43:56-44:06' '44:06-44:08' '44:08-44:11' '44:11-44:12'\n",
      " '44:12-44:13' '44:14-44:15' '44:15-44:16' '44:20-44:22' '44:22-44:26'\n",
      " '44:28-44:36' '44:38-44:41' '44:41-44:47' '44:48-45:15' '45:15-45:29'\n",
      " '45:30-45:33' '45:34-45:38' '45:39-45:39' '45:43-45:54' '45:56-46:00'\n",
      " '46:01-46:01' '46:02-46:06' '46:07-46:14' '46:15-46:17' '46:18-46:18'\n",
      " '46:20-46:22' '46:23-46:26' '46:27-46:27' '46:28-46:36' '46:37-46:38'\n",
      " '46:39-46:41' '46:41-46:43' '46:44-46:44' '46:46-46:48' '46:49-46:51'\n",
      " '46:56-47:03' '47:03-47:05' '47:06-47:45' '47:46-47:47' '47:48-47:51'\n",
      " '47:52-48:07' '48:07-48:18' '48:19-48:19' '48:19-48:55' '48:56-49:11'\n",
      " '49:15-49:21' '49:24-49:36' '49:37-49:38' '49:39-49:58' '50:01-50:04'\n",
      " '50:05-50:08' '50:09-50:15' '50:15-50:22' '50:22-50:24' '50:28-50:31'\n",
      " '50:32-50:33' '50:38-50:39' '50:53-51:05' '51:06-51:21' '51:44-51:48'\n",
      " '51:51-51:53' '51:55-51:58' '52:15-52:43' '52:43-53:03' '53:03-53:05'\n",
      " '53:08-53:14' '53:15-57:19' '57:19-57:38' '57:43-57:43' '58:32-58:35']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_out.loc[sub_fixed.index, [\"timestamp_continuous\",\"global_start_sec\",\"global_end_sec\",\"resets_detected_here\"]] = \\\n"
     ]
    }
   ],
   "source": [
    "# === Make timestamps continuous for ALL ABI_S15 master sessions and OVERWRITE `timestamp` ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIG ---\n",
    "in_path   = \"/Users/maxchalekson/Projects/NICO-Research/NICO_human-gemini/Data/utterance_data_aligned_full.csv\"\n",
    "out_full  = \"/Users/maxchalekson/Projects/NICO-Research/NICO_human-gemini/Data/utterance_data_aligned_full_continuous_overwritten.csv\"\n",
    "out_s15   = \"/Users/maxchalekson/Projects/NICO-Research/NICO_human-gemini/Data/utterance_data_ABI_S15_continuous_overwritten.csv\"\n",
    "\n",
    "# --- LOAD (preserve original order) ---\n",
    "df = pd.read_csv(in_path)\n",
    "df[\"_orig_row_order\"] = np.arange(len(df), dtype=np.int64)\n",
    "orig_len = len(df)\n",
    "\n",
    "# --- Target rows: anything with \"ABI_S15\" in session/global_session ---\n",
    "def _contains_s15(x):\n",
    "    s = str(x) if pd.notna(x) else \"\"\n",
    "    return \"ABI_S15\" in s\n",
    "\n",
    "has_session = \"session\" in df.columns\n",
    "has_global  = \"global_session\" in df.columns\n",
    "\n",
    "session_mask = df[\"session\"].map(_contains_s15) if has_session else pd.Series(False, index=df.index)\n",
    "global_mask  = df[\"global_session\"].map(_contains_s15) if has_global else pd.Series(False, index=df.index)\n",
    "mask_target  = session_mask | global_mask\n",
    "\n",
    "if not mask_target.any():\n",
    "    raise ValueError(\"No rows found that look like ABI_S15 in 'session' or 'global_session'.\")\n",
    "\n",
    "# --- Build a stitch key that prefers the master 'session' over clip-level ids ---\n",
    "stitch_key = pd.Series(np.nan, index=df.index, dtype=object)\n",
    "if has_session:\n",
    "    stitch_key.loc[session_mask] = df.loc[session_mask, \"session\"]\n",
    "if has_global:\n",
    "    # fill any remaining ABI_S15 rows (where session didn't match) with their global_session\n",
    "    fill_mask = mask_target & stitch_key.isna()\n",
    "    stitch_key.loc[fill_mask] = df.loc[fill_mask, \"global_session\"]\n",
    "\n",
    "df[\"_stitch_key\"] = stitch_key\n",
    "\n",
    "# --- Helpers ---\n",
    "_time_pat = re.compile(r'(\\d{1,2}:\\d{2}(?::\\d{2})?)')\n",
    "\n",
    "def parse_hhmmss_to_sec(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).strip()\n",
    "    if not s: return np.nan\n",
    "    parts = s.split(\":\")\n",
    "    try:\n",
    "        parts = [float(p) for p in parts]\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "    if len(parts) == 3:\n",
    "        h, m, sec = parts\n",
    "    elif len(parts) == 2:\n",
    "        h, m, sec = 0.0, parts[0], parts[1]\n",
    "    elif len(parts) == 1:\n",
    "        h, m, sec = 0.0, 0.0, parts[0]\n",
    "    else:\n",
    "        return np.nan\n",
    "    return h*3600 + m*60 + sec\n",
    "\n",
    "def split_timestamp_robust(ts):\n",
    "    \"\"\"Return (start_sec, end_sec) from 'mm:ss-mm:ss' or 'hh:mm:ss-hh:mm:ss' or bracketed variants.\"\"\"\n",
    "    s = \"\" if pd.isna(ts) else str(ts)\n",
    "    hits = _time_pat.findall(s)\n",
    "    if len(hits) >= 2:\n",
    "        return parse_hhmmss_to_sec(hits[0]), parse_hhmmss_to_sec(hits[1])\n",
    "    elif len(hits) == 1:\n",
    "        v = parse_hhmmss_to_sec(hits[0]); return v, v\n",
    "    else:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "def fmt_mmss(total_seconds: float) -> str:\n",
    "    total_seconds = int(round(float(total_seconds)))\n",
    "    m, s = divmod(total_seconds, 60)\n",
    "    return f\"{m:02}:{s:02}\"\n",
    "\n",
    "def make_timestamps_continuous_one_group(group: pd.DataFrame, tol: float = 2.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert local timestamps to a continuous session clock for ONE stitch group (master session).\n",
    "    - Reset detected when local start < previous local end.\n",
    "    - Only the FIRST near-zero row in a consecutive run starts a new clip.\n",
    "    - No row cuts/reorders (iterate in original order).\n",
    "    \"\"\"\n",
    "    g = group.copy()\n",
    "\n",
    "    # Prefer numeric start/end if present; else parse from 'timestamp'\n",
    "    start_num = pd.to_numeric(g.get(\"start_sec\", np.nan), errors=\"coerce\")\n",
    "    end_num   = pd.to_numeric(g.get(\"end_sec\",   np.nan), errors=\"coerce\")\n",
    "\n",
    "    starts_local, ends_local = [], []\n",
    "    for idx, ts in g[\"timestamp\"].items():\n",
    "        s_txt, e_txt = split_timestamp_robust(ts)\n",
    "        s_val = start_num.loc[idx] if pd.notna(start_num.loc[idx]) else s_txt\n",
    "        e_val = end_num.loc[idx]   if pd.notna(end_num.loc[idx])   else (e_txt if not np.isnan(e_txt) else s_val)\n",
    "        s_val = 0.0 if np.isnan(s_val) else float(s_val)\n",
    "        e_val = s_val if np.isnan(e_val) else float(e_val)\n",
    "        starts_local.append(s_val)\n",
    "        ends_local.append(e_val)\n",
    "\n",
    "    starts_local = np.asarray(starts_local, dtype=float)\n",
    "    ends_local   = np.asarray(ends_local,   dtype=float)\n",
    "\n",
    "    offset = 0.0\n",
    "    fixed_starts, fixed_ends = [], []\n",
    "    resets = 0\n",
    "    prev_near_zero = False\n",
    "\n",
    "    for i, (s_local, e_local) in enumerate(zip(starts_local, ends_local)):\n",
    "        near_zero = (s_local <= tol)\n",
    "        is_reset = False\n",
    "        if i > 0:\n",
    "            went_backwards = s_local < (ends_local[i-1] - 1e-9)\n",
    "            if went_backwards:\n",
    "                # Only the FIRST near-zero in a run starts a new clip; any non-near-zero back-jump also starts one\n",
    "                if (near_zero and not prev_near_zero) or (not near_zero):\n",
    "                    is_reset = True\n",
    "\n",
    "        if is_reset:\n",
    "            # Set (not add) offset to previous FIXED end so we don't double-count\n",
    "            offset = fixed_ends[-1]\n",
    "            resets += 1\n",
    "\n",
    "        fixed_s = s_local + offset\n",
    "        fixed_e = e_local + offset\n",
    "        fixed_starts.append(fixed_s)\n",
    "        fixed_ends.append(fixed_e)\n",
    "\n",
    "        prev_near_zero = near_zero\n",
    "\n",
    "    g[\"global_start_sec\"]     = fixed_starts\n",
    "    g[\"global_end_sec\"]       = fixed_ends\n",
    "    g[\"timestamp_continuous\"] = [f\"{fmt_mmss(s)}-{fmt_mmss(e)}\" for s, e in zip(fixed_starts, fixed_ends)]\n",
    "    g[\"resets_detected_here\"] = resets  # same value within this group\n",
    "\n",
    "    return g\n",
    "\n",
    "# --- Process only the ABI_S15 subset, stitched by the master session key (_stitch_key) ---\n",
    "df_out = df.copy()\n",
    "sub = df_out.loc[mask_target].copy()\n",
    "\n",
    "if \"_stitch_key\" not in sub.columns:\n",
    "    raise ValueError(\"Internal stitch key missing.\")\n",
    "\n",
    "stitched = []\n",
    "for key, g in sub.groupby(\"_stitch_key\", sort=False):\n",
    "    stitched.append(make_timestamps_continuous_one_group(g, tol=2.0))\n",
    "sub_fixed = pd.concat(stitched, axis=0)\n",
    "\n",
    "# --- Overwrite timestamp + keep backup for affected rows ---\n",
    "df_out.loc[sub_fixed.index, \"timestamp_local\"] = df_out.loc[sub_fixed.index, \"timestamp\"]\n",
    "df_out.loc[sub_fixed.index, \"timestamp\"] = sub_fixed[\"timestamp_continuous\"]\n",
    "\n",
    "# Also store continuous second columns in the full DF\n",
    "for col in [\"timestamp_continuous\",\"global_start_sec\",\"global_end_sec\",\"resets_detected_here\"]:\n",
    "    if col not in df_out.columns:\n",
    "        df_out[col] = np.nan\n",
    "df_out.loc[sub_fixed.index, [\"timestamp_continuous\",\"global_start_sec\",\"global_end_sec\",\"resets_detected_here\"]] = \\\n",
    "    sub_fixed[[\"timestamp_continuous\",\"global_start_sec\",\"global_end_sec\",\"resets_detected_here\"]]\n",
    "\n",
    "# --- Per-master-session durations BEFORE dropping helper columns ---\n",
    "dur_rows = []\n",
    "s15_out = df_out.loc[mask_target].copy()\n",
    "for key, g in s15_out.groupby(df.loc[mask_target, \"_stitch_key\"], sort=False):\n",
    "    s = float(pd.to_numeric(g[\"global_start_sec\"], errors=\"coerce\").min())\n",
    "    e = float(pd.to_numeric(g[\"global_end_sec\"],   errors=\"coerce\").max())\n",
    "    total = e - s\n",
    "    dur_rows.append({\n",
    "        \"stitch_key(session)\": key,\n",
    "        \"rows\": len(g),\n",
    "        \"resets_detected\": int(g[\"resets_detected_here\"].iloc[0]) if \"resets_detected_here\" in g.columns else 0,\n",
    "        \"duration_sec\": total,\n",
    "        \"duration_hms\": f\"{int(total//3600)}:{int((total%3600)//60):02}:{int(total%60):02}\",\n",
    "    })\n",
    "dur = pd.DataFrame(dur_rows).sort_values(\"duration_sec\", ascending=False)\n",
    "\n",
    "# --- Restore exact original order and assert row count unchanged ---\n",
    "df_out = df_out.sort_values(\"_orig_row_order\").reset_index(drop=True)\n",
    "assert len(df_out) == orig_len, \"Row count changed — content was cut, which should not happen.\"\n",
    "\n",
    "# --- SAVE (drop helper cols only at write time) ---\n",
    "Path(out_full).parent.mkdir(parents=True, exist_ok=True)\n",
    "# Keep helper columns in the saved files? If not, drop them:\n",
    "save_full = df_out.drop(columns=[\"_orig_row_order\", \"_stitch_key\"], errors=\"ignore\")\n",
    "save_s15  = save_full.loc[mask_target]\n",
    "\n",
    "save_full.to_csv(out_full, index=False)\n",
    "save_s15.to_csv(out_s15, index=False)\n",
    "\n",
    "print(f\"Done. Kept all rows: {orig_len}.\")\n",
    "print(f\"• Wrote full file: {out_full}\")\n",
    "print(f\"• Wrote ABI S15-only file: {out_s15}\")\n",
    "print(\"\\nPer-master-session ABI_S15 durations:\")\n",
    "print(dur.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9100957c",
   "metadata": {},
   "source": [
    "using the utterance_data_ABI_S15_continuous_overwritten.csv\n",
    "\n",
    "The `global_start_sec` works correctly even though it ends on the 58th minute approximately.\n",
    "\n",
    "But somehow that's only the last of the transcripts pulled out?\n",
    "\n",
    "I had checked across the JSON file of transcripts and that's the last one from EV's GitHub so this is all I can do for this part right now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b6328",
   "metadata": {},
   "source": [
    "### breaking down into sentence as the \"smallest unit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3aff5a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote sentence units -> /Users/maxchalekson/Projects/NICO-Research/NICO_human-gemini/Data/sentences_ABI_S15.csv\n",
      "Rows (utterances): 255  |  Rows (sentences): 497\n",
      "Sentences with estimated times: 457 / 497\n"
     ]
    }
   ],
   "source": [
    "# === Split transcripts into sentence-level units (with light tags + estimated per-sentence times) ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# -------- CONFIG --------\n",
    "in_path  = \"/Users/maxchalekson/Projects/NICO-Research/NICO_human-gemini/Data/utterance_data_ABI_S15_continuous_overwritten.csv\"\n",
    "out_path = \"/Users/maxchalekson/Projects/NICO-Research/NICO_human-gemini/Data/sentences_ABI_S15.csv\"\n",
    "\n",
    "# If you want to include equal-time estimates for each sentence in an utterance:\n",
    "ADD_SENT_TIME_ESTIMATES = True\n",
    "\n",
    "# -------- LOAD --------\n",
    "df = pd.read_csv(in_path)\n",
    "if \"transcript\" not in df.columns:\n",
    "    raise ValueError(\"Expected a 'transcript' column in the input CSV.\")\n",
    "\n",
    "# Keep a stable order\n",
    "df[\"_row_id\"] = np.arange(len(df))\n",
    "\n",
    "# Normalize some columns if present\n",
    "for col in [\"transcript\",\"speaker\",\"session\",\"global_session\",\"timestamp\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# -------- Sentence splitter (robust-ish) --------\n",
    "# Avoid splitting on common abbreviations (e.g., \"Dr.\", \"e.g.\", \"i.e.\", etc.)\n",
    "ABBR_TERMINALS = {\n",
    "    \"mr.\",\"mrs.\",\"ms.\",\"dr.\",\"prof.\",\"sr.\",\"jr.\",\"vs.\",\"etc.\",\"e.g.\",\"i.e.\",\n",
    "    \"al.\",\"fig.\",\"figs.\",\"eq.\",\"eqs.\",\"cf.\",\"inc.\",\"ltd.\",\"co.\",\"corp.\",\"dept.\"\n",
    "}\n",
    "\n",
    "# Backchannels we may want to merge into neighboring sentences\n",
    "BACKCHANNELS = {\n",
    "    \"ok\",\"okay\",\"okay.\",\"ok.\",\"yes\",\"yeah\",\"yep\",\"right\",\"mm-hmm\",\"mhm\",\"uh-huh\",\n",
    "    \"sounds good\",\"sounds good.\",\"sure\",\"great\",\"thanks\",\"thank you\",\"cool\",\"nice\",\n",
    "    \"works for me\",\"fine by me\",\"let's do it\",\"lets do it\",\"i'm in\",\"im in\"\n",
    "}\n",
    "\n",
    "# Dialogue-act regexes (very lightweight)\n",
    "PROPOSAL_PATTERNS = [\n",
    "    r\"\\blet'?s\\b\", r\"\\b(shall we|should we|could we|can we)\\b\",\n",
    "    r\"\\b(do you want to|wanna)\\b\", r\"\\b(how about|what if|why don'?t we)\\b\",\n",
    "]\n",
    "ACCEPTANCE_PATTERNS = [\n",
    "    r\"\\b(sounds (good|great)|works for me|fine by me|that works|all good)\\b\",\n",
    "    r\"^(ok|okay|yes|yeah|yep|sure|alright)\\b\", r\"\\b(let'?s do it|count me in|i'?m in|im in|sgtm)\\b\",\n",
    "]\n",
    "REJECTION_PATTERNS = [r\"\\b(no|not now|maybe later|can'?t|cannot|won'?t|don'?t think so)\\b\"]\n",
    "QUESTION_MARKERS   = [r\"\\?$\", r\"^(who|what|when|where|why|how)\\b\"]\n",
    "\n",
    "def naive_split(text: str):\n",
    "    \"\"\"Split on sentence enders while protecting abbreviations.\"\"\"\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    # Split on punctuation that ends a sentence, keeping it with the sentence\n",
    "    parts = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    parts = [p for p in parts if p]\n",
    "    if not parts:\n",
    "        return []\n",
    "\n",
    "    merged = [parts[0]]\n",
    "    for p in parts[1:]:\n",
    "        prev = merged[-1]\n",
    "        prev_tail = prev.strip().lower().split()[-1] if prev.strip() else \"\"\n",
    "        if prev_tail in ABBR_TERMINALS:\n",
    "            merged[-1] = prev + \" \" + p\n",
    "        else:\n",
    "            merged.append(p)\n",
    "    # Clean stray quotes/spaces\n",
    "    return [m.strip(' \"\\'').strip() for m in merged if m.strip()]\n",
    "\n",
    "def is_backchannel(s: str) -> bool:\n",
    "    t = re.sub(r\"[^\\w\\s?.!-]\", \"\", (s or \"\").lower()).strip()\n",
    "    return (t in BACKCHANNELS) or (len(t) <= 12 and t in {\"ok\",\"okay\",\"yes\",\"yeah\",\"yep\",\"right\",\"cool\",\"nice\"})\n",
    "\n",
    "def attach_intra_row_backchannels(s_list):\n",
    "    \"\"\"Attach short backchannels to the previous sentence to avoid standalones.\"\"\"\n",
    "    if not s_list: return []\n",
    "    cleaned, buf = [], []\n",
    "    for s in s_list:\n",
    "        if is_backchannel(s):\n",
    "            if cleaned:\n",
    "                cleaned[-1] = (cleaned[-1] + \" \" + s).strip()\n",
    "            else:\n",
    "                buf.append(s)\n",
    "        else:\n",
    "            if buf:\n",
    "                s = \" \".join(buf) + \" \" + s\n",
    "                buf = []\n",
    "            cleaned.append(s.strip())\n",
    "    if buf and cleaned:\n",
    "        cleaned[-1] = (cleaned[-1] + \" \" + \" \".join(buf)).strip()\n",
    "    elif buf and not cleaned:\n",
    "        cleaned = [\" \".join(buf)]\n",
    "    return cleaned\n",
    "\n",
    "def any_match(pats, s): \n",
    "    return any(re.search(p, (s or \"\").lower()) for p in pats)\n",
    "\n",
    "def classify_dialogue_act(sentence: str) -> str:\n",
    "    s = (sentence or \"\").strip().lower()\n",
    "    if any_match(ACCEPTANCE_PATTERNS, s): return \"Acceptance\"\n",
    "    if any_match(REJECTION_PATTERNS, s):  return \"Rejection/Deferral\"\n",
    "    if any_match(PROPOSAL_PATTERNS, s) and not re.search(r\"\\blet me\\b\", s): return \"Proposal/Offer\"\n",
    "    if any_match(QUESTION_MARKERS, s):    return \"Question\"\n",
    "    return \"Inform/Report\"\n",
    "\n",
    "# -------- Build sentence-level rows --------\n",
    "rows = []\n",
    "\n",
    "# Columns we’ll try to carry through if present\n",
    "carry_cols = [c for c in [\n",
    "    \"global_session\",\"session\",\"speaker\",\"timestamp\",\n",
    "    \"global_start_sec\",\"global_end_sec\",\"clip_number\"\n",
    "] if c in df.columns]\n",
    "\n",
    "df = df.sort_values([\"_row_id\"]).reset_index(drop=True)\n",
    "\n",
    "for i, r in df.iterrows():\n",
    "    utt = r.get(\"transcript\", \"\")\n",
    "    sents = naive_split(utt)\n",
    "    sents = attach_intra_row_backchannels(sents)\n",
    "\n",
    "    # Optional: estimate per-sentence times by evenly splitting the utterance span\n",
    "    start_g = float(r.get(\"global_start_sec\")) if \"global_start_sec\" in r and pd.notna(r[\"global_start_sec\"]) else np.nan\n",
    "    end_g   = float(r.get(\"global_end_sec\"))   if \"global_end_sec\"   in r and pd.notna(r[\"global_end_sec\"])   else np.nan\n",
    "    dur     = end_g - start_g if (np.isfinite(start_g) and np.isfinite(end_g)) else np.nan\n",
    "\n",
    "    n = max(len(sents), 1)\n",
    "    per = (dur / n) if (ADD_SENT_TIME_ESTIMATES and np.isfinite(dur) and dur > 0) else np.nan\n",
    "\n",
    "    for j, s in enumerate(sents or [utt], start=1):\n",
    "        row = {\n",
    "            \"source_row_index\": i,\n",
    "            \"sent_index_in_row\": j,\n",
    "            \"sentence\": s,\n",
    "            \"dialogue_act\": classify_dialogue_act(s),\n",
    "        }\n",
    "        # Carry through identifying columns\n",
    "        for c in carry_cols:\n",
    "            row[c] = r.get(c)\n",
    "\n",
    "        # Estimated per-sentence times\n",
    "        if ADD_SENT_TIME_ESTIMATES and np.isfinite(per):\n",
    "            est_start = start_g + per * (j - 1)\n",
    "            est_end   = start_g + per * j\n",
    "            row[\"sent_start_sec_est\"] = est_start\n",
    "            row[\"sent_end_sec_est\"]   = min(end_g, est_end)\n",
    "        else:\n",
    "            row[\"sent_start_sec_est\"] = np.nan\n",
    "            row[\"sent_end_sec_est\"]   = np.nan\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "df_sent = pd.DataFrame(rows).sort_values(\n",
    "    [\"source_row_index\",\"sent_index_in_row\"], kind=\"mergesort\"\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# -------- SAVE --------\n",
    "Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "df_sent.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Wrote sentence units -> {out_path}\")\n",
    "print(f\"Rows (utterances): {len(df)}  |  Rows (sentences): {len(df_sent)}\")\n",
    "if ADD_SENT_TIME_ESTIMATES:\n",
    "    with_times = df_sent[\"sent_start_sec_est\"].notna().sum()\n",
    "    print(f\"Sentences with estimated times: {with_times} / {len(df_sent)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26e1a347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/maxchalekson/Projects/NICO-Research/NICO_human-gemini/Data/sentences_ABI_S15_filled.csv\n",
      "Rows total: 497\n",
      "Missing sent_start_sec_est: 0\n",
      "Missing sent_end_sec_est:   0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/lphw45ds14n5t74zwjdfybx40000gn/T/ipykernel_95466/2717668370.py:117: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  merged = merged.groupby(\"utter_row_idx\", group_keys=False, dropna=False).apply(fill_group)\n"
     ]
    }
   ],
   "source": [
    "# === Fill missing sentence time estimates from parent utterance spans ===\n",
    "# - Merges sentence rows with their parent utterance via `source_row_index`\n",
    "# - Uses parent numeric times (global_start_sec/global_end_sec) if present\n",
    "# - Else parses parent timestamp strings (timestamp or timestamp_continuous)\n",
    "# - Evenly divides the utterance duration across its sentences\n",
    "# - Guarantees no NaNs remain in sent_start_sec_est / sent_end_sec_est\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIG (edit these paths for your machine) ---\n",
    "sentences_path  = \"/Users/maxchalekson/Projects/NICO-Research/NICO_human-gemini/Data/sentences_ABI_S15.csv\"\n",
    "utterances_path = \"/Users/maxchalekson/Projects/NICO-Research/NICO_human-gemini/Data/utterance_data_ABI_S15_continuous_overwritten.csv\"\n",
    "out_path        = \"/Users/maxchalekson/Projects/NICO-Research/NICO_human-gemini/Data/sentences_ABI_S15_filled.csv\"\n",
    "\n",
    "# --- Load ---\n",
    "sents = pd.read_csv(sentences_path)\n",
    "utts  = pd.read_csv(utterances_path)\n",
    "\n",
    "# Sanity: need this to map sentences back to the utterance row they came from\n",
    "if \"source_row_index\" not in sents.columns:\n",
    "    raise ValueError(\"Expected 'source_row_index' in the sentence file to map back to utterances.\")\n",
    "\n",
    "# Build a stable utterance row index (original file order)\n",
    "utts = utts.copy()\n",
    "utts[\"utter_row_idx\"] = np.arange(len(utts), dtype=np.int64)\n",
    "\n",
    "# Keep only what's useful from utterances (robust to column presence)\n",
    "def present(cols, df_cols): return [c for c in cols if c in df_cols]\n",
    "need_from_utts = [\"utter_row_idx\", \"global_start_sec\", \"global_end_sec\",\n",
    "                  \"timestamp\", \"timestamp_continuous\"]\n",
    "avail = present(need_from_utts, utts.columns)\n",
    "utts_sub = utts[avail].copy()\n",
    "\n",
    "# Avoid name collisions: rename timestamp strings\n",
    "if \"timestamp\" in utts_sub.columns:\n",
    "    utts_sub = utts_sub.rename(columns={\"timestamp\": \"utter_timestamp\"})\n",
    "if \"timestamp_continuous\" in utts_sub.columns:\n",
    "    utts_sub = utts_sub.rename(columns={\"timestamp_continuous\": \"utter_timestamp_continuous\"})\n",
    "\n",
    "# Merge sentences with parent utterances\n",
    "merged = sents.merge(utts_sub, left_on=\"source_row_index\", right_on=\"utter_row_idx\", how=\"left\")\n",
    "\n",
    "# --- Helpers to parse \"mm:ss-mm:ss\" or \"hh:mm:ss-hh:mm:ss\" ---\n",
    "_time_pat = re.compile(r'(\\d{1,2}:\\d{2}(?::\\d{2})?)')\n",
    "\n",
    "def parse_hhmmss_to_sec(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).strip()\n",
    "    if not s: return np.nan\n",
    "    parts = s.split(\":\")\n",
    "    try:\n",
    "        parts = [float(p) for p in parts]\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "    if len(parts) == 3:\n",
    "        h, m, sec = parts\n",
    "    elif len(parts) == 2:\n",
    "        h, m, sec = 0.0, parts[0], parts[1]\n",
    "    elif len(parts) == 1:\n",
    "        h, m, sec = 0.0, 0.0, parts[0]\n",
    "    else:\n",
    "        return np.nan\n",
    "    return h*3600 + m*60 + sec\n",
    "\n",
    "def split_timestamp_robust(ts):\n",
    "    s = \"\" if pd.isna(ts) else str(ts)\n",
    "    hits = _time_pat.findall(s)\n",
    "    if len(hits) >= 2:\n",
    "        return parse_hhmmss_to_sec(hits[0]), parse_hhmmss_to_sec(hits[1])\n",
    "    elif len(hits) == 1:\n",
    "        v = parse_hhmmss_to_sec(hits[0]); return v, v\n",
    "    else:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "# Ensure the target columns exist\n",
    "for col in [\"sent_start_sec_est\", \"sent_end_sec_est\"]:\n",
    "    if col not in merged.columns:\n",
    "        merged[col] = np.nan\n",
    "\n",
    "# --- Core fill logic (applied per utterance) ---\n",
    "def fill_group(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    # If every sentence already has estimates, skip\n",
    "    need = g[\"sent_start_sec_est\"].isna() | g[\"sent_end_sec_est\"].isna()\n",
    "    if not need.any():\n",
    "        return g\n",
    "\n",
    "    # Prefer parent numeric times\n",
    "    start_parent = pd.to_numeric(g.get(\"global_start_sec\"), errors=\"coerce\").iloc[0] if \"global_start_sec\" in g else np.nan\n",
    "    end_parent   = pd.to_numeric(g.get(\"global_end_sec\"),   errors=\"coerce\").iloc[0] if \"global_end_sec\"   in g else np.nan\n",
    "\n",
    "    # Fallback: parse parent's timestamp strings\n",
    "    if (not np.isfinite(start_parent)) or (not np.isfinite(end_parent)):\n",
    "        s1, e1 = split_timestamp_robust(g[\"utter_timestamp\"].iloc[0]) if \"utter_timestamp\" in g else (np.nan, np.nan)\n",
    "        s2, e2 = split_timestamp_robust(g[\"utter_timestamp_continuous\"].iloc[0]) if \"utter_timestamp_continuous\" in g else (np.nan, np.nan)\n",
    "        start_parent = s1 if np.isfinite(s1) else (s2 if np.isfinite(s2) else start_parent)\n",
    "        end_parent   = e1 if np.isfinite(e1) else (e2 if np.isfinite(e2) else end_parent)\n",
    "\n",
    "    # Last resort: tiny non-NaN span to avoid downstream errors\n",
    "    if (not np.isfinite(start_parent)) or (not np.isfinite(end_parent)) or end_parent < start_parent:\n",
    "        start_parent = 0.0 if not np.isfinite(start_parent) else float(start_parent)\n",
    "        end_parent   = start_parent + 1e-6\n",
    "\n",
    "    # Evenly space across sentences in this utterance\n",
    "    n = len(g)\n",
    "    step = (end_parent - start_parent) / n if n > 0 else 0.0\n",
    "    starts = [start_parent + i * step for i in range(n)]\n",
    "    ends   = [start_parent + (i + 1) * step for i in range(n)]\n",
    "\n",
    "    g.loc[:, \"sent_start_sec_est\"] = starts\n",
    "    g.loc[:, \"sent_end_sec_est\"]   = ends\n",
    "    return g\n",
    "\n",
    "# Apply per-utterance (grouped by the row index from the utterance table)\n",
    "merged = merged.groupby(\"utter_row_idx\", group_keys=False, dropna=False).apply(fill_group)\n",
    "\n",
    "# Guard: any residual NaNs -> fill with safe defaults\n",
    "resid = merged[\"sent_start_sec_est\"].isna() | merged[\"sent_end_sec_est\"].isna()\n",
    "if resid.any():\n",
    "    merged.loc[resid, \"sent_start_sec_est\"] = merged.loc[resid, \"sent_start_sec_est\"].fillna(0.0)\n",
    "    merged.loc[resid, \"sent_end_sec_est\"]   = merged.loc[resid, \"sent_end_sec_est\"].fillna(1e-6)\n",
    "\n",
    "# Drop helper cols (optional)\n",
    "final = merged.drop(columns=[c for c in [\"utter_row_idx\", \"utter_timestamp\", \"utter_timestamp_continuous\"] if c in merged.columns])\n",
    "\n",
    "# --- Save ---\n",
    "Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "final.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Wrote: {out_path}\")\n",
    "print(f\"Rows total: {len(final)}\")\n",
    "print(\"Missing sent_start_sec_est:\", final['sent_start_sec_est'].isna().sum())\n",
    "print(\"Missing sent_end_sec_est:  \", final['sent_end_sec_est'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2018c8",
   "metadata": {},
   "source": [
    "The file that is in use now is `sentences_ABI_S15_filled.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d3b87",
   "metadata": {},
   "source": [
    "So now just working on the cosine similarity idea with the global time stamp and the sentences as the \"smallest unit\" from this point and below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b88193",
   "metadata": {},
   "source": [
    "## Idea 3 - merge small speaker runs - unecessary?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conv-clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
