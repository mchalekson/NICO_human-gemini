Event 1 @ 690.0s (Â±25s)
=========================

[667.0s] Yevgenia Kozorovitskiy: So, I and I think there are some ways to think about light sheet applications as related to depth, but its primary power is in gentleness and speed and not necessarily in depth.
[668.0s] Alexandra Dickinson: I have a question about it kind of ties into something we were talking about in our last breakout session, so not most of you weren't there, but um, we were talking about how fluorescence is very, very specific to certain molecules, a single molecule and how some of the other really cool imaging techniques that have are have a lot of use are not as specific. I'm wondering for photoacoustic imaging, you know, I hear a lot about detecting hemoglobin and I assume that's because it's very concentrated and has sort of spectral properties that are that are easy to detect using a photoacoustic imaging. What other kinds of molecules can you detect and um, yeah, what is the kind of specificity?
[668.0s] Sixian You: Exactly because the ballistic photons decay exponentially with depth.
[671.0s] Aniruddha Ray: Oh, there is Stephen Barbara. So Danny, can see you. Hey Danny.
[671.0s] Brad Smith: Yeah, let's put a pin in that and if we find we have a bit of uh a bit of a lag, we'll come back to that. I I want to help Jazz out a little bit because she's the only one in the whole conference I think doing plants and it seemed to me that plants have got like something around the outside so sticking an electrode into a plant might be the way to go. Is has that ever been thought about or uh what what's the problem that we could help you with, Jazz?
[673.0s] Brad Smith: Yeah.
[675.0s] Barbara Smith: Sorry, sorry. I have a little human that required me for a few minutes.
[675.0s] Brad Smith: Are there methods beyond confocal and light sheet to address 3D regions deep within a tissue sample.
[677.0s] Brad Smith: Um, maybe we should um, either we can go to the Google document um, to start starting our bullet points since Andrew set out now the chopper.
[680.0s] Barbara Smith: Yeah, I'd be glad I'd be glad to navigate.
[680.0s] Yevgenia Kozorovitskiy: But if you think about, you know, broadly light shaping applications, I think would be would have been a better word to put there because light sheet to me it means that you rely somehow on camera based, um, sensor imaging, but light shaping applications are super broad and can rely on point detectors as well as camera based imaging and any kind of sensor that you want. And that's where I think there's a lot of
[682.0s] Aniruddha Ray: Um, so, uh, my name is Anirud. I'm from University of Toledo. I work on two different things. So I work on nanotechnology aided optical imaging, which involves fluorescence as well as photoacoustics. And that's what is my interest in deep tissue imaging. I also work on lensless holographic microscopy, um, but that is more for Xvivo samples or in vitro samples. So we basically develop different types of nanoparticles, um, metallic quantum dots, um, um, polymeric nanoparticles for biomedical imaging, sensing, as well as for therapy, uh, chemotherapy, photodynamic therapy. And we monitor them using fluorescence and photoacoustics, as well as some scattering and other things.
[682.0s] Brad Smith: That seems to me rather and some of you people are really focused on that. So where do you see in the next five years, let's say beyond light sheet, uh, how to how do people view that?
[685.0s] Brad Smith: You call it an electrode. I'm a little confused as an outsider. Why do you use the word electrode? That implies to me electrochemistry.
[690.0s] Aniruddha Ray: Sure, I can start to summarize and we can conclude this discussion.
[692.0s] Barbara Smith: Yeah, so we do it's electrophysiology. So um the micropipette electrode um was developed I think it's around the 1960s and um they record neuronal activity. It's a high resolution recording of typically single neurons um and their activity level um with the with the um basically I won't go into detail. Um so the electrode is placed into the brain and um it's typically done either um blind or um using optical microscopy approaches from from external sources. So uh a microscope on the outside. And and so what ends up happening is if you have um if you work with this blind, you would use like probably a DIC microscope and um you can do this in vivo and the electrode is placed in and uh positive pressure is is pushed into the electrode as it's moved through the brain tissue so that that electrode doesn't get clogged. The tip of the electrode is about um one to three microns in diameter and that electrode is is moved little very very very slowly into the brain um and there's no way to target selective cells of interest using the blind approach, but you can get deeper, right? So um the only way the most basic way that they know that they've hit a cell of interest is by creating a connection between that electrode and that cell. So they place it from a positive pressure and then we make a negative pressure from that. We create a bleb, so it sucks up part of that membrane of the cell. Um we um increase the pressure and it opens up the cell membrane so that there's a direct connection between that electrode and the fluids within the electrode and the cell um solution. And and what ends up happening is the um it ends up being able to record that cell, but you don't know what cell you're hitting until you start recording it. And if you've started recording the wrong cell, you have to remove that micropipette electrode um throw it out, place a new one in and then enter into the brain one more time. And so uh it's kind of a hunt and peck process. You can get deeper and people can record very well uh neuroscientists have been recording like that for for decades. Um but lately with two photon microscopy, you can get down to about a millimeter and you can genetically alter or place in different kinds of dyes and and selectively target neurons up to a millimeter. But past the millimeter from the cortical surface, um there are minimal ways to do it. So you can suction out a portion of the brain. Um that's one way to do it and then the animal is still alive and you can move down um and you can do within a millimeter of whatever area you've sectioned. Um or if you're coming from the top, you can see cells about within a millimeter of of where that surface is. If you're exceptional if you're doing three photon or multi photon, you can get maybe two millimeters. Um it's a little bit rough. Um but the way that we're doing this is oh oh is we're integrating light and sound into that micropipette electrode so you don't need a microscope on the outside to guide that cell. And so um we can get uh stains and genetic um uh genetic contrast throughout the brain and now we can we can tap into cells um of interest at at depths beyond one millimeter as deep as that. So we're combining um blind and an imaging guided approach by doing this, but without the microscope on the outside. Hope that made sense.
[695.0s] Brad Smith: Let's uh, let's.
[696.0s] Aniruddha Ray: One point, are we, are we on slide 55 or should we be on 54?
[699.0s] Alexandra Dickinson: I mean, I was thinking that would be really cool and I don't think it's been done to my knowledge. Um, so I think that would be something pretty exciting to try. I mean, I was just thinking, you know, as everybody was talking, um, something like you can think of plants are as super regenerators, right? Like a a bamboo plant for instance, if you ever have bamboo in your yard and you're trying to get rid of it, it's not going to happen. Like that plan is going to grow back. You can chop it down, you can cut off the roots, it will grow back. So it would be really cool to to look at a tissue like that that's really thick. Um, if you could get, you know, a centimeter or two into that tissue and and look at the, you know, the regeneration processes. I think that would be really cool application of of this kind of technology that uh has not been to my knowledge done at all before.
[701.0s] Brad Smith: Yeah, we're 54, 3.4, deep tissue imaging.
[704.0s] Brad Smith: And some of you are working exactly on this problem. So, you know, you can pump up why you're going to solve it, uh,
[705.0s] Yevgenia Kozorovitskiy: engineering, uh, that relates to depth where you have to kind of think separately about excitation delivery and then also, uh, as as as Sian thinks about a lot also getting back that information out somehow.
[709.0s] Brad Smith: Oh, so we've gone and put our names in the wrong one, have we?
[712.0s] Aniruddha Ray: Yeah.
[714.0s] Brad Smith: So should someone want to cut and paste that?
[714.0s] Carolyn Bayer: Yeah, so we use ICG, you know, um, so we're typically imaging in the near infrared, um, far near infrared if we can get those dyes. Um, and you know, I'll often talk to people who are developing fluorescent probes who have failures that aren't fluorescent. You know, so those are the ones that we can image well.
