
Scratch Notes for human-gemini


extract_utterances_data.py

Parses valid session JSONs to extract utterance-level data (speaker, transcript, annotations, gestures, etc.) into flat CSV

-----------------------------------------------------------------------------------------------

extracted_utterance_data.csv

Used to analyze behavior, idea flow, and group dynamics across meetings




This massive code script (under the Parsing Transcripts from CSV section):

- spent majority of Friday working on this code script. Based on what I want it to do..
it is fine. It is mostly the edge cases. I don't need it to be perfect

So then âœ… Suggested next step (Week of July 21):
Since you're ready to explore the ideas you mentioned, I recommend:
(just a general direction, can always adjust):

- Create a first_speaker flag for each session
- Use start_sec_adjusted to identify early utterances
- Filter for those that include explain or define term or contain keywords like â€œI'mâ€ or â€œMy researchâ€
- Count participants per session with df['speaker'].nunique()
- Compute meeting_length = df.groupby('session')['end_sec_adjusted'].max()





----------------------------- So far: Week of July 21

ğŸ”¨ Suggested Implementation Path
âœ… [Done] Speaker-level influence table with explained_early
ğŸ“Š Visualize & regress on existing flags
ğŸ§  Add number of participants per session (could be another explanatory variable)
ğŸ§µ Parse transcript column for intro/research expertise flags (new feature: mentions_research)
ğŸ”„ Merge it into your speaker_stats table
ğŸ” Extend regression to include mentions_research as a predictor of influence


As of 17:53 on July 23, This is what I now need to do:

1. Transcript Keyword Parsing

2. Speaker Influence Modeling

3. Regression Analysis 

4. (optional) Agreement or Mislabeling Audit
