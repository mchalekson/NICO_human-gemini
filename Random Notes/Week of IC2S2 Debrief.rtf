{\rtf1\ansi\ansicpg1252\cocoartf2821
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Because I would mainly discuss to her during the call \'97 but i feel that I didn\'92t end up doing that much\'85 \
\
Within all of this, and I note, I managed to create a global timestamp, as much of the conferences were split into clips. because I was also attempting to see if these splits also affected Gemini\'92s annotations of \'91presents new idea\'92, \'91expand on existing idea\'92, or similar codes from the first version of the codebook \
\
\
Computed per-minute frequencies of is_explanation, has_new_idea, and is_self_intro across all speakers and sessions (how did I end up calculating these frequencies) \
- Then created ratio features (e.g. idea-to-explanation)\
- This then established a behavioral signature for each speaker\
\
I had also built OLS regression models to predict is_explanation_per_min from other code features\'85 some of the key findings were the following:\
- Both has_new_idea_per_min and is_self_intro_per_min are strong, significant predictors\
- Adding interaction terms and session length (total_minutes) slightly improved R^2\
- This all highlights how Gemini\'92s predictions of explanatory behavior may be tightly coupled with these contextual cues.\
\
I exported and inspected the top residual speakers - those who observed explanation behavior was much higher than predicted \'97 flagging moments where Gemini may under detect important contributions\
- These were moments when the definition in the codebook itself was underspecified. For e.g., in several high-residual cases, Gemini didn\'92t mark something as an \'93explanation\'94, even though the speaker was clearly building on prior ideas. This led back to our idea of wanting to reengineer the codebook, including the idea of counterexamples\
- This also leads to the idea that maybe Gemini can detect \'93implied reasoning\'94, or \'93non-traditional explanation formats\'94 -> again, we would need to teach it in what to look for (essentially edge cases)\'85 what I was looking into for the failure cases, or why did in the \'91annotated_high_residuals_tagged.csv\'92 file did it fail all its \'91failure_category\'92 column\
\
I also tried to see if early explainers would lead to something, etc. Like how many explanations were done in the first X minutes, and if that really made a difference\
\
I had also tried to do a Per-Conference Analysis for num_decisions, num_new_ideas, num_explanations along with num_unique_speakers\
\
I had also done transcript analyses seeing if their specific research led to insights \'97 didn\'92t get too far on this one as much as I would\'92ve liked (analyzing the person\'92s specific research background specific keyword extraction) \'97 TLDR most speakers don\'92t explicitly make decisions regardless when they introduce themselves. At times analyzing the transcript was a hit or miss.\
\
\
\
Again this is whether we can have Gemini annotate out a recorded conference session based on our written code book (23) behaviors and see if those annotations can predict macro-level behaviors based on the micro-level behaviors. \
\
\pard\pardeftab720\sa240\partightenfactor0

\f1 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 but i know also she has so many inishgts from the conferenceetc. but she wants to hear my thoughts, even if we end up using some of my ideas plus ideas she's foudn from the conferenc , and that's why she;s writing it up\
}